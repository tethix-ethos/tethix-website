---
title: Pathfinders Newmoonsletter, September 2024
date: 2024-09-03
description: While Big Tech refuses to embrace the demure and mindful trend, we sing to a burning planet, explore some recent research on LLMs, and wonder whether AI chatbots could help us get our sh*t together.
---

<p>As the moon completes another orbit around Earth, the Pathfinders Newmoonsletter rises in your inbox to inspire
  collective pathfinding towards better tech futures.</p>
<p>We sync our monthly reflections to the lunar cycle as a reminder of our place in the Universe and a commonality we
  share across timezones and places we inhabit. New moon nights are dark and hence the perfect time to gaze into the
  stars and set new intentions.</p>
<p>With this Newmoonsletter, crafted around the Tethix campfire, we invite you to join other Pathfinders as we reflect
  on celestial movements in tech in the previous lunar cycle, water our ETHOS Gardens, and plant seeds of intentions for
  the new cycle that begins today.</p>
<h2><strong>Tethix Weather Report</strong></h2>
<p><strong>üî• Current conditions: Even corn is sweating hard in this scorching AI summer as fire practitioners keep
    burning money, people, and the planet to keep their golem kilns running</strong></p>
<p>This AI summer is getting so hot that even corn is sweating heavily in the US Midwest, where fire practitioners just
  happen to be building new data centers with lower cooling bills. Now, the multiplying data centers that are used as
  kilns for AI golems are not the only thing that‚Äôs making corn sweat on our warming planet. But the rising emissions
  the fire practitioners are trying to carbon-account away are sure to keep increasing cooling costs, regardless of
  where they try to tax-evade next. So unless the plan is to harvest corn sweat for data center cooling, it might be
  time for the fire practitioners to cool it a bit with their world domination plans.&nbsp;<em>(See:&nbsp;<a
      href="https://www.scientificamerican.com/article/corn-sweat-and-climate-change-bring-sweltering-weather-to-the-midwest/">‚ÄòCorn
      Sweat‚Äô and Climate Change Bring Sweltering Weather to the Midwest</a>,&nbsp;<a
      href="https://www.datacenterknowledge.com/build-design/the-move-to-improve-why-the-midwest-is-housing-more-data-centers">The
      Move to Improve: Why the Midwest is Housing More Data Centers</a>, and&nbsp;<a
      href="https://www.ft.com/content/2d6fc319-2165-42fb-8de1-0edf1d765be3">How Big Tech is quietly trying to reshape
      how pollution is reported</a>)</em></p>
<p>After all, a recent ruling has found Google‚Äôs fire practitioners to be already winning the game of Monopoly they‚Äôre
  playing with our search queries. Strangely enough, the new apple-flavored AI golems that will be unleashed onto our
  made-in-the-global-South devices, might soon be answering more questions that might otherwise be ‚Äúgoogled‚Äù. Thus,
  helping Google‚Äôs fire practitioners argue they are but a humble tech startup trying to earn an honest dime with ads
  nobody wants to click on.&nbsp;<em>(See:&nbsp;<a
      href="https://www.firstpost.com/tech/googles-monopoly-ruling-may-adversely-affect-apple-will-apple-intelligence-come-to-its-rescue-13801396.html">Google's
      'monopoly' ruling may adversely affect Apple. Will Apple Intelligence come to its rescue?</a>)</em></p>
<p>Speaking of power-hungry tech mages pretending to be but humble apprentices interested in benefiting rather than
  exploiting humanity. Powerful fire practitioners have discovered a new shade of morally gray by realizing they can
  acquire potential competitors without actually acquiring them, thus avoiding regulatory scrutiny. So, when we say that
  ChatGPT appears to have a stronger moral compass than its makers, we want to remind everyone that the bar is getting
  lower every day.&nbsp;<em>(See:&nbsp;<a
      href="https://www.nytimes.com/2024/08/08/technology/ai-start-ups-google-microsoft-amazon.html">The New A.I. Deal:
      Buy Everything but the Company</a>)</em></p>
<p>But we get it. It‚Äôs hard trying to convince your shareholders that you‚Äôll continue growing forever, while at the same
  time convincing regulators that you‚Äôre nothing more than an innovative tech startup that‚Äôs creating jobs
  for&nbsp;<s>AI golems</s>&nbsp;humans. And to also keep up with the incessant demands for growth while you‚Äôre burning
  money on golem kilns and fees, you sometimes have to sacrifice a couple of thousands of humans to
  appease&nbsp;<s>Moloch</s>&nbsp;shareholders.&nbsp;<em>(See:&nbsp;<a
      href="https://www.reuters.com/technology/artificial-intelligence/swedens-klarna-says-ai-chatbots-help-shrink-headcount-2024-08-27/">Sweden's
      Klarna says AI chatbots help shrink headcount</a>)</em></p>
<p>We cannot help but wonder: who will be paying for all these magic AI golems as the well-paid tech workforce shrinks
  to the bare minimum, and fewer people can afford multiple, increasingly expensive subscription services? We suppose
  that is a concern for another quarter. For now,&nbsp;<s>Moloch</s>&nbsp;shareholders have been appeased, and the data
  centers have not yet been flooded or incinerated in wildfires.</p>
<p>And hey, perhaps we‚Äôll all finally get the increase in abundance, leisure time, and more just distribution of wealth
  that tech-enabled progress was supposed to enable. And enough disposable income to afford several subscription-based
  AI companions, on top of groceries! As of now, the 15-hour workweek Keynes predicted back in the 1930s still seems
  like science fiction and the details of how our obsession with growth is going to keep us within planetary boundaries
  remain vague. Ah, wait. We almost forgot. AGI. Miracle energy source. AI fixes climate. Immortality. Got
  it.&nbsp;<em>(See:&nbsp;<a
      href="https://www.technologyreview.com/2024/08/27/1096148/ray-kurzweil-futurist-ai-medicine-advances-freedom/">Ray
      Kurzweil: Technology will let us fully realize our humanity</a>,&nbsp;<a
      href="https://tethix.substack.com/p/what-should-we-do-with-the-time-that">What should we do with the time that new
      technologies save?</a>, and&nbsp;<a
      href="https://www.ted.com/talks/johan_rockstrom_the_tipping_points_of_climate_change_and_where_we_stand?subtitle=en">The
      tipping points of climate change ‚Äî and where we stand</a>)</em></p>
<p>You see how the fire practitioners of Silicon Valley are willing to bet everything and everyone for a chance of
  winning the AI race? Not very demure, not very mindful. But as they continue releasing their AI golems into the
  devices and apps we rely on, we wonder whether their golems can be enlisted to help us make more mindful decisions. In
  a special&nbsp;<a href="https://tethix.substack.com/p/a-chat-with-chatgpt-on-ai-chatbots">bonus episode</a>&nbsp;of
  Pathfinders Podcast, we interview ChatGPT to explore how these AI golems could help humanity rebuild communication
  bridges, and think different.</p>
<p>And we hope that the seeds we have collected for this Newmoonsletter can help&nbsp;<em>you</em>&nbsp;explore
  perspectives that might just lead to paths where we are able to preserve a liveable planet for our children. A human
  can still dream, right? (At least until fire practitioners force us to upload our consciousness into the cloud.)</p>
<h2><strong>Tethix Elemental seeds</strong></h2>
<h3 class="fire">Fire seeds to stoke your Practice</h3>
<p>As generative AI approaches the&nbsp;<a
    href="https://theconversation.com/generative-ai-hype-is-ending-and-now-the-technology-might-actually-become-useful-236940">peak
    of inflated expectation</a>, many people still fall on the extremes ends of the&nbsp;<a
    href="https://tethix.co/air/6-reasons-why-we-need-responsible-firekeeping-in-tech/">spectrum of
    responses</a>&nbsp;to generative AI.</p>
<p>On the freezing end that doesn‚Äôt want to touch gen AI with a stick, people are still dismissing the potential of
  Large Language Models (LLMs) due to their&nbsp;<a
    href="https://www.theguardian.com/technology/article/2024/aug/06/ai-llms">limitations</a>&nbsp;and biases. If you
  fall on this end, you might want to explore today‚Äôs&nbsp;<a
    href="https://interconnected.org/home/2024/07/19/ai-landscape">gen AI product landscape</a>&nbsp;with a bit more
  curiosity, even if it is just to provide better criticism.</p>
<p>On the other, wildfire end of the spectrum, full of unbridled enthusiasm, people see LLMs as the only tool they‚Äôll
  ever need and try to hammer down every (in)possible task with them. If you fall on this end, it might help to get a
  broader sense of what it takes to develop an LLM application, and&nbsp;<a
    href="https://bdtechtalks.substack.com/p/how-i-approach-llm-application-development">this three-stage
    framework</a>&nbsp;by Ben Dickson is a good starting point.</p>
<p>If you‚Äôre like us, you probably fall somewhere in between and realize that the choice of whether to use LLMs should
  ideally be based on more than just a financial spreadsheet and benchmark performance. The development of LLMs is
  filled with ethical dilemmas of all shapes and sizes. As a recent Vox article explores, it might actually be&nbsp;<a
    href="https://www.vox.com/future-perfect/364384/its-practically-impossible-to-run-a-big-ai-company-ethically">impossible
    to run a big AI company ethically</a>&nbsp;given how Anthropic ‚Äì which was supposed to be an ethical haven for
  OpenAI refugees ‚Äì has been acting lately.</p>
<p>At least Anthropic is a bit more open than OpenAI when it comes to&nbsp;<a
    href="https://techcrunch.com/2024/08/26/anthropic-publishes-the-system-prompt-that-makes-claude-tick/">sharing
    system prompts</a>&nbsp;that define Claude‚Äôs personality and style. Along with&nbsp;<a
    href="https://www.theverge.com/2024/8/5/24213861/apple-intelligence-instructions-macos-15-1-sequoia-beta">uncovered
    system prompts</a>&nbsp;for Apple‚Äôs upcoming AI assistant, LLMs'&nbsp;<a
    href="https://docs.anthropic.com/en/release-notes/system-prompts">system prompts</a>&nbsp;provide a fascinating look
  inside the ‚Äúminds‚Äù of LLMs and how they might be inclined to interact if left to their own devices.</p>
<p>That said, OpenAI did recently release a&nbsp;<a href="https://openai.com/index/gpt-4o-system-card">GPT-4o System
    Card</a>&nbsp;that reports on how catastrophically risky their latest publicly available model is. We appreciate the
  transparency, but it‚Äôs worth noting that GPT-4o‚Äôs persuasive capabilities have crossed into what OpenAI defines as
  medium risk threshold. Even OpenAI openly acknowledges that the anthropomorphization and emotional reliance on models
  such as GPT-4o is a societal impact worthy of further scrutiny. So even if you think LLMs are nothing more than
  stochastic parrots, we think we should all be a bit more curious about how LLMs make humans&nbsp;<em>feel</em>&nbsp;as
  they become increasingly convincing imitators of human interactions.</p>
<p>And while we appreciate these glimpses into how the most popular LLMs work and affect their users, we‚Äôre still
  holding our breath when it comes to environmental transparency. We‚Äôre still waiting for the day when OpenAI,
  Anthropic, Google, Microsoft, Meta &amp; co. decide to share the environmental costs of their large models, instead of
  trying to&nbsp;<a
    href="https://www.irishtimes.com/business/2024/08/14/amazon-meta-and-big-techs-bid-to-rewrite-the-rules-on-net-zero/">rewrite
    the rules on net zero</a>. (If you‚Äôre unsure about what net zero even means, we highly recommend checking out
  the&nbsp;<a href="https://learn.greensoftware.foundation/climate-commitments">Climate commitments section</a>&nbsp;in
  the free Green Software Practitioner course.)</p>
<p>At least we can now look forward to the day when regulations such as the EU AI Act will force these providers of
  general-purpose AI models to disclose the&nbsp;<a
    href="https://rtl.chrisadams.me.uk/2024/08/does-the-eu-ai-act-really-call-for-tracking-inference-as-well-as-training-in-ai-models/">energy
    consumption</a>&nbsp;of their models. In fact, the European Commission is currently&nbsp;<a
    href="https://digital-strategy.ec.europa.eu/en/funding/artificial-intelligence-act-call-tenders-measure-and-foster-energy-efficient-and-low-emission">looking
    for proposals</a>&nbsp;on how to best measure and report these emissions. We‚Äôre definitely with Sasha Luccioni and
  others who wonder:&nbsp;<a href="https://www.nature.com/articles/d41586-024-02680-3">Light bulbs have energy ratings ‚Äî
    so why can‚Äôt AI chatbots?</a></p>
<p>And while energy consumption is just a part of the environmental impact puzzle, we have to start somewhere. Given the
  current need for&nbsp;<a
    href="https://www.ted.com/talks/johan_rockstrom_the_tipping_points_of_climate_change_and_where_we_stand?subtitle=en">decisive
    climate action</a>, knowing the planetary cost of generative AI might help us rethink how we deploy and use these
  technologies.</p>
<h3 class="air">Air seeds to improve the flow of Collaboration</h3>
<p>But let‚Äôs be honest: while having more data and transparency would be welcome, we should also remind ourselves that
  we already know what needs to be done to ease our pressure on planetary boundaries and hopefully avoid the worst-case
  climate scenarios. We just can‚Äôt seem to agree to act on the science and implement existing ideas into practice at the
  scale that‚Äôs required. Given that LLMs can access vast amounts of this knowledge and also seem to be pretty
  good&nbsp;<a href="https://importai.substack.com/p/import-ai-382-ai-systems-are-societal">societal mirrors</a>, could
  they help us, humans, collaborate and thus act better?</p>
<p>Various AI assistants and companions are already starting to play a bigger role in our lives, prompting some to
  rebrand AI as&nbsp;<a
    href="https://www.technologyreview.com/2024/08/05/1095600/we-need-to-prepare-for-addictive-intelligence/">‚Äúaddictive
    intelligence‚Äù</a>, especially when it comes to&nbsp;<a
    href="https://www.the74million.org/article/ai-companions-are-patient-funny-upbeat-and-probably-rewiring-kids-brains/">kids
    and younger adults</a>.&nbsp;<a
    href="https://blog.ialja.com/2024/08/07/ai-emotional-lock-in-competitive-advantage/">AI emotional
    lock-in</a>&nbsp;is certainly something to watch out for, especially as companies look for new monetization
  opportunities while at the same time making AI chatbots more human-like.</p>
<p>In our podcast, we managed to have a pretty decent&nbsp;<a
    href="https://tethix.substack.com/p/a-chat-with-chatgpt-on-ai-chatbots">group voice chat with ChatGPT</a>, and it
  appears that the upcoming Advanced Voice Mode will&nbsp;<a
    href="https://techcrunch.com/2024/08/17/openais-new-voice-mode-let-me-talk-with-my-phone-not-to-it/">further improve
    this experience</a>. As already mentioned, even OpenAI decided to highlight the potential for emotional reliance in
  their recently released System Card ‚Äì especially when it comes to&nbsp;<a
    href="https://www.wired.com/story/openai-voice-mode-emotional-attachment/">ChatGPT‚Äôs Voice Mode</a>&nbsp;‚Äì, which
  might also be used to nudge people towards action.</p>
<p>As our interactions with AI chatbots become more persuasive, we should also keep in mind the human tendency to
  perceive machines as impartial ‚Äì which might make&nbsp;<a
    href="https://tethix.substack.com/p/should-we-use-ai-chatbots-as-mediators">AI chatbots trustworthy mediators in
    human affairs</a>. Recent research seems to indicate that AI assistants do have a&nbsp;<a
    href="https://techxplore.com/news/2024-08-ai-impacts-attention-teams.html">strong influence on team discussions</a>.
  And&nbsp;<a
    href="https://news.mit.edu/2024/ai-assistant-monitors-teamwork-promote-effective-collaboration-0819">another group
    of researchers</a>&nbsp;is exploring how well-timed AI interventions might help improve alignment within teams and
  help humans follow critical procedures. And while the US mayoral candidate who promised to govern with the assistance
  of a fine-tuned LLMs&nbsp;<a
    href="https://www.theguardian.com/us-news/article/2024/aug/21/wyoming-cheyenne-ai-bot-mayor">was not elected</a>,
  people are already collaborating with AI chatbots in different contexts, both in 1-to-1 and group settings.</p>
<p>So perhaps AI chatbots could actually help us rebuild communication bridges in our increasingly polarized world,
  especially online, where we should also explore&nbsp;<a
    href="https://accidentalgods.life/governable-spaces-solve-for-democracy-on-the-internet-and-our-outer-politics-becomes-a-lot-more-sane-with-nathan-schneider/">more
    democratic governance approaches</a>. We do hope that AI chatbots will not be used just to attend meetings in our
  place and quietly summarize ‚Äúkey takeaways‚Äù ‚Äì an area where it seems we already need to&nbsp;<a
    href="https://dataethics.eu/im-unable-to-attend-but-ill-send-my-ai-assistent/">develop a clear etiquette</a>.
  Instead, AI chatbots could help us find common ground, encourage equal participation, and perhaps even remind us about
  the ethical and sustainability commitments our companies made on their websites.</p>
<h3 class="earth">Earth seeds to ground you in Research</h3>
<p>Of course, even ChatGPT kept reminding us about its biases and limitations during our podcast interview. While we do
  have glimpses of the system prompts that define the behavior of some of the most popular AI chatbots, we still don‚Äôt
  know what exactly is going on in LLMs‚Äô ‚Äúminds‚Äù.</p>
<p>Recent research is showing us that LLMs can already&nbsp;<a href="https://arxiv.org/abs/2407.08853">appear more human
    than humans</a>, that they&nbsp;<a
    href="https://venturebeat.com/ai/llms-excel-at-inductive-reasoning-but-struggle-with-deductive-tasks-new-research-shows/">excel
    at inductive reasoning but struggle with deductive tasks</a>, and that they might&nbsp;<a
    href="https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814">develop
    their own understanding of reality as their language abilities improve</a>.</p>
<p>A new&nbsp;<a href="https://metr.org/blog/2024-08-06-update-on-evaluations/">METR general capability
    evaluation</a>&nbsp;has also found that&nbsp;<em>‚Äúthe GPT-4o agent completes around 60% of the tasks that our human
    baseliners completed in less than 15 minutes, but can complete around 10% of tasks with human baselines that took
    over 4 hours.‚Äù</em>&nbsp;Using LLM-based agents on tasks they are able to complete is also unsurprisingly
  cheaper:&nbsp;<em>‚Äú(‚Ä¶) the average cost of using an LM agent is around 1/30th of the cost of the median hourly wage of
    a US bachelor‚Äôs degree holder.‚Äù</em>&nbsp;We‚Äôd like to remind anyone seeing these results and thinking they can fire
  their expensive human workers that the devil with all machine learning is still in well-defined tasks.</p>
<p>And obviously, LLMs and other AI systems pose additional serious risks besides being faster and cheaper than humans.
  To help you keep track of how things can go mildly to horribly wrong,&nbsp;<a
    href="https://venturebeat.com/ai/mit-releases-comprehensive-database-of-ai-risks/">MIT has released a database of AI
    risks</a>. Their&nbsp;<a href="https://airisk.mit.edu/">AI Risk Repository</a>&nbsp;<em>‚Äúcaptures 700+ risks
    extracted from 43 existing frameworks‚Äù</em>. And if that isn‚Äôt enough for you, you can also head to the&nbsp;<a
    href="https://wiki.aiimpacts.org/">AI Impacts Wiki</a>&nbsp;to explore burning questions about the good, the bad,
  and the ugly side of AI.</p>
<p>Meanwhile, we are wondering when we‚Äôll reference the first research paper autonomously written and published by
  an&nbsp;<a
    href="https://venturebeat.com/ai/sakana-ai-scientist-conducts-research-autonomously-challenging-scientific-norms/">AI
    Scientist</a>. We also wonder how the AI researchers will deal with the dreaded human&nbsp;<a
    href="https://arstechnica.com/science/2020/06/empirical-analysis-tells-reviewer-2-go-f-yourself/">Reviewer #2</a>?
  Perhaps all peer reviewers will become AI-powered and thus more mindful with the feedback they provide to their peers?
  The race for the highest impact score is sure to get interesting as more AI researchers enter the academic publishing
  arena, either openly or in the shadows.</p>
<p>At least both human and AI researchers can now reference a new&nbsp;<a
    href="https://arstechnica.com/information-technology/2024/08/debate-over-open-source-ai-term-brings-new-push-to-formalize-definition/">draft
    definition of what open-source AI is</a>&nbsp;‚Äì and what it isn‚Äôt. And, ‚Äì surprise, surprise! ‚Äì, Mark Zuckerberg‚Äôs
  Meta‚Äôs Llama 3 does not meet the OSI defined criteria due to its license and usage restrictions, despite Zuck‚Äôs
  attempts to rebrand himself as an&nbsp;<a
    href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/">open-source AI evangelist</a>. And
  while the OSI definition doesn‚Äôt require the release of raw training data, the model provider should include enough
  information about the data that was used, and the code that was used for training.</p>
<p>Will the new definition lead to less open-source-washing? Probably not. But we should celebrate whenever a group of
  highly opinionated humans manage to agree on something! (With or without AI assistance.)</p>
<h3 class="water">Water seeds to deepen your Reflection</h3>
<p>Now, take a deep breath. If you‚Äôre dealing with a bit of anxiety after reading this Newmoonsletter ‚Äì or any other
  news, really ‚Äì we‚Äôd like to reassure you that this might be a perfectly healthy reaction to the lunacy of tech and
  modernity more broadly. Listening to Rachel Donald‚Äôs discussion with Steffi Bednarek, a climate psychotherapist, on
  the&nbsp;<a href="https://www.planetcritical.com/p/sick-people-or-sick-society-steffi">latest episode</a>&nbsp;of the
  Planet: Critical podcast might help you feel less alone.</p>
<p>And if you‚Äôre looking for a bit of fiction to escape to, while still exploring how we might face our current
  challenges, we suggest checking out&nbsp;<a
    href="https://www.permaculture.co.uk/articles/any-human-power-by-manda-scott/">Any Human Power</a>&nbsp;by Manda
  Scott. (Her podcast&nbsp;<a href="https://accidentalgods.life/our-podcast/">Accidental Gods</a>&nbsp;is also a good
  source of inspiring ideas and people.)</p>
<p>But when you truly need a break from it all, put on&nbsp;<a href="https://earth.fm/">Earth.fm</a>&nbsp;and listen to
  nature sounds from different corners of our wonderful planet. And get out there when it‚Äôs not too hot, place your
  hands on a tree, and express some gratitude to the more than human life that has made all of this possible</p>
<h3>A music seed to sing &amp; dance along</h3>
<p>Michael Jackson released Earth Song in 1995, when the&nbsp;<a
    href="https://climate.copernicus.eu/climate-indicators/temperature">average global temperature</a>&nbsp;was about
  0.5 ¬∞C above the pre-industrial average. We‚Äôre now at around 1.2 ¬∞C and already&nbsp;<a
    href="https://www.bbc.com/news/science-environment-68110310">starting to breach</a>&nbsp;the Paris-agreed climate
  threshold of 1.5 ¬∞C. Globally, we‚Äôre still burning about 1.6 times more&nbsp;<a
    href="https://ourworldindata.org/fossil-fuels">fossil fuels</a>&nbsp;than in 1995 ‚Äì every year!</p>
<p>Keep in mind that this song was released before Google launched, before we had smartphones in our pockets, before
  cloud computing, and before the internet had enough data to train an LLM. Yet, the song‚Äôs message and MJ‚Äôs cries still
  resonate even more loudly today, almost 30 years later.</p>
<a href="https://www.youtube.com/watch?v=XAi3VTSdTxU"><img src="https://tethix.co/wp-content/uploads/2024/09/michael-jackson-earth-song.jpg" alt=""></a>
<blockquote>
  <p><em>Did you ever stop to notice<br>All the blood we've shed before?<br>Did you ever stop to notice<br>This crying
      Earth, this weeping shore?</em></p>
  <p><em>‚Ä¶</em></p>
  <p><em>What about nature's worth? (Ooh)<br>It's our planet's womb (What about us?)<br>What about animals? (What about
      it?)<br>Turned kingdom to dust (What about us?)</em></p>
  <p><em>‚Ä¶</em></p>
</blockquote>
<h2><strong>Pathfinders Podcast</strong></h2>
<a href="https://tethix.co/pathfinders/#podcast"><img src="https://tethix.co/wp-content/uploads/2024/04/pathfinders-podcast.png" class="podcast-card"></a>
<p>If you‚Äôd like to keep exploring the lunacy of tech with us, we invite you to listen and subscribe to the&nbsp;<a
    href="https://tethix.co/pathfinders/#podcast">Pathfinders Podcast</a>&nbsp;wherever you get your podcasts. The
  podcast is a meandering exploration inspired by the seeds planted in the Newmoonsletter at the beginning of the
  lunation cycle, and the paths illuminated during the Full Moon Gathering.</p>
<p>The question that emerged in the&nbsp;<a
    href="https://tethix.substack.com/p/pathfinders-newmoonsletter-august">August Newmoonsletter</a>&nbsp;and guided our
  discussion was:&nbsp;<strong><a href="https://tethix.substack.com/p/should-we-use-ai-chatbots-as-mediators">Should we
      use AI chatbots as mediators in human affairs?</a></strong>&nbsp;This episode was inspired by our observations
  that ChatGPT seems to have a stronger moral compass than its makers. When asked about the ethics of questionable
  business decisions such as using people‚Äôs voices without their consent, ChatGPT presents diverse considerations from
  different points of view and advocates for upholding ethical standards. This made us wonder: would executives like Sam
  Altman make more ethical decisions if they were using their creations in day-to-day moral deliberations? And even more
  broadly, could we use Large Language Models (LLMs) such as ChatGPT to help us communicate better, resolve
  interpersonal conflicts and tensions, and perhaps even make better collective decisions?</p>
<p>And because it didn‚Äôt feel right to keep talking about ChatGPT without getting its perspective, we recorded a special
  bonus episode with ChatGPT as our guest of honor. In the follow-up episode&nbsp;<strong><a
      href="https://tethix.substack.com/p/a-chat-with-chatgpt-on-ai-chatbots">A chat with ChatGPT on AI chatbots as
      mediators</a></strong>, we play with the limits of LLMs and ChatGPT‚Äôs Voice Mode to explore human and AI biases,
  and the potential benefits of AI-supported mediation. We try to imagine how collaborative AI tools might help humans
  communicate better, how organizations like OpenAI might develop these tools more responsibly by experimenting with
  different governance models, and other considerations that Kai helps us surface. In the second half of the episode, we
  provide additional insights into the how and why of the episode and our hopes to inspire curiosity and playfulness in
  the ways we explore the potential of AI chatbots.</p>
<a href="https://tethix.substack.com/p/a-chat-with-chatgpt-on-ai-chatbots"><img src="https://tethix.co/wp-content/uploads/2024/08/chat-with-chatgpt-youtube-thumbnail.jpg" alt=""></a>
<p>To capture the full awkwardness and curiosity of chatting with an AI guest, we also recorded the bonus episode on
  video. You can head over to&nbsp;<a href="https://www.youtube.com/watch?v=EDEMlbdJ9iU">YouTube</a>&nbsp;to see what
  happens when two humans and a robot&nbsp;<s>walk into a bar</s>&nbsp;record a podcast. Both episodes are also
  available in audio-only format wherever you get your podcasts.</p>
<p>Take a listen and join us at the next&nbsp;<a href="https://tethix.co/pathfinders/#full-moon">Full Moon
    Gathering</a>&nbsp;if you‚Äôd like to illuminate additional paths for our next episode!</p>
<h2><strong>Your turn, Pathfinders.</strong></h2>
<h3>Join us for the Pathfinders Full Moon Gathering</h3>
<p>In this lunation cycle, we‚Äôre inviting Pathfinders to gather around our virtual campfire to explore the
  question:&nbsp;<strong>How do we embrace the lunacy of tech with playfulness?</strong>&nbsp;‚Äì but it‚Äôs quite likely
  that our discussion will take other meandering turns as well.</p>
<a href="https://lu.ma/p1qpjenn"><img src="https://tethix.co/wp-content/uploads/2024/09/pathfinders-full-moon-gathering_2024-09-18.png"  class="full-moon-card" alt=""></a>
<p>So, pack your curiosity, moral imagination, and smiles, and join us around the virtual campfire for our next
  üåï&nbsp;<strong><a href="https://lu.ma/p1qpjenn">Pathfinders Full Moon Gathering</a>&nbsp;on Wednesday, September 18
    at 5PM AEST / 9AM CEST</strong>, when the moon will once again be illuminated by the sun.</p>
<p>This is a free and casual open discussion, but please be sure to&nbsp;<a href="https://lu.ma/p1qpjenn">sign
    up</a>&nbsp;so that we can lug an appropriate number of logs around the virtual campfire. And yes, friends who don‚Äôt
  have the attention span for the Newmoonsletter are also welcome, as long as they reserve their&nbsp;<a
    href="https://lu.ma/p1qpjenn">seat on the logs</a>.</p>
<h3>Keep on finding paths on your own</h3>
<p>If you can‚Äôt make it to our Full Moon Pathfinding session, we still invite you to make your own! If anything emerges
  while reading this Newmoonsletter, write it down. You can keep these reflections for yourself or share them with
  others. If it feels right, find the Reply button ‚Äì or comment on this post ‚Äì and share your reflections with us. We‚Äôd
  love to feature Pathfinders reflections in upcoming Newmoonsletters and explore even more diverse perspectives.</p>
<p>And if you‚Äôve enjoyed this Newmoonsletter or perhaps even cracked a smile, we‚Äôd appreciate it if you shared it with
  your friends and colleagues.</p>
<p>The next Newmoonsletter will rise again during the next new moon. Until then, build some communication bridges, get
  to know the trees in your neighborhood, and be mindful about the seeds of intention you plant and the stories you
  tell. There‚Äôs magic in both.</p>
<p>With üôÇ from the Tethix campfire,<br>Alja and Mat</p>
<div>
  <hr>
</div>
